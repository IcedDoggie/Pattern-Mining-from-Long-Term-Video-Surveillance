{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###### import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "import sklearn\n",
    "from pandas import Series, DataFrame, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as fig\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import collections as mc \n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "##################################### Tunable Variables ###########################################\n",
    "days_to_process = 7\n",
    "pd.options.display.max_rows = 10\n",
    "###################################################################################################\n",
    "\n",
    "#####################################string variables##############################################\n",
    "dayArray = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17'\n",
    ",'18','19','20','21','22','23','24','25','26','27','28','29','30','31']\n",
    "monthArray = ['01','02','03','04','05','06','07','08','09','10','11','12',]\n",
    "# Tunable Variables\n",
    "# currentYear = 2013 # input 1\n",
    "# pointerMonth = n n1\t   # input 2\n",
    "# pointerDay = 0   # input 3\n",
    "\n",
    "currentYear = 2012\n",
    "currentMonth = monthArray[0]\n",
    "currentDay = dayArray[0]\n",
    "pointerMonth = 0\n",
    "pointerDay = 0\n",
    "daysToChoose = 235 # currently hardcoded, 235 is for entire year of 2012\n",
    "#####################################################################################################\n",
    "\n",
    "###############################string concatenation & Load Data########################\n",
    "counter = 0\n",
    "frames = pd.DataFrame()\n",
    "# os.chdir('E:\\Documents\\MMU Studies\\Python Scripts\\Track Blobs')\n",
    "os.chdir('E:\\Documents\\MMU Studies\\Python Scripts\\Track LOST dataset')\n",
    "currentIndex = 1 # This variable is used to reindex every dataframe\n",
    "print(os.getcwd())\n",
    "listDay = []\n",
    "# list season is a list for specifying spring, summer or winter in the visualization\n",
    "listSeason = []\n",
    "listDate = []\n",
    "listDate += [0]\n",
    "listDate_for_topbottom = []\n",
    "listDate_for_topbottom += [0]\n",
    "while counter < daysToChoose:\n",
    "    stringDate = '001_' + str(currentYear) + str(currentMonth) + str(currentDay) + '.txt' \n",
    "    string_to_be_parsed = \"pd.read_table('\" + stringDate + \"',delimiter=' ', header=None, names=col_names)\"\n",
    "    try:\n",
    "        exec(\"%s%d = %s\" % (\"day\", counter, string_to_be_parsed))\n",
    "        tempString_Date = eval(\"%s%d\" % (\"day\", counter))\n",
    "        tempString_Date, currentIndex = trackID_reindex(tempString_Date, currentIndex)\n",
    "        tempList = tempString_Date[['X', 'Y']]\n",
    "        frames = frames.append(tempString_Date)\n",
    "        tempFrames = frames[['X', 'Y']]\n",
    "        listDay += [tempList]\n",
    "        listSeason += [currentMonth]\n",
    "        date = str(currentYear) + str(currentMonth) + str(currentDay)\n",
    "        if counter%6==0:\n",
    "            listDate += [date]\n",
    "        if counter%20 == 0:\n",
    "            listDate_for_topbottom += [date]\n",
    "#         print(\"Found\")\n",
    "    except:\n",
    "#         print(\"Not Found\")\n",
    "        counter -= 1\n",
    "    \n",
    "    counter += 1\n",
    "    currentYear, currentMonth, currentDay, pointerMonth, pointerDay = calendarFunction(currentYear, currentMonth, currentDay, pointerMonth, pointerDay)\n",
    "#######################################################################################\n",
    "col_names = ['TrackID','FrameNo', 'X', 'Y']\n",
    "concatDay = frames.sort_values(by='TrackID', ascending=True)\n",
    "concatDay = concatDay.reset_index(drop=True)\n",
    "os.chdir('E:\\Documents\\MMU Studies\\Python Scripts')\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "# heatmap_data = constructHeatmap(concatDay)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "axis_counter = 0\n",
    "np_vector_heatmap = []\n",
    "np_mat = []\n",
    "np_mat2 = []\n",
    "np_mat_topbottom = np.empty((48,0)) # 48 is the total number of pools\n",
    "\n",
    "while counter < daysToChoose:\n",
    "    heatmap_data = constructHeatmap(listDay[counter])\n",
    "    vector_heatmap, sum_array, sum_array_top_bottom = heatmapPooling(heatmap_data, 80)\n",
    "    np_mat += [sum_array]\n",
    "    np_mat2 += [sum_array_top_bottom]\n",
    "    np_mat_topbottom = np.insert(np_mat_topbottom, 0, sum_array_top_bottom, axis = 1)\n",
    "    np_vector_heatmap += [vector_heatmap]\n",
    "    counter += 1\n",
    "    axis_counter += 1\n",
    "\n",
    "np_vector_heatmap = np.asarray(np_vector_heatmap)\n",
    "# np_mat_transpose = list(map(list, zip(*np_mat))) #cannot transpose cuz it only changes the sides\n",
    "# print(np_mat_transpose)\n",
    "# print(max(np_mat[0]))\n",
    "# print(min(np_mat[0]))\n",
    "clustered_data = agglomerativeClustering(heatmap_data, np_mat)\n",
    "# test_transpose_of_topbottom = np_mat_topbottom.transpose()\n",
    "\n",
    "#2012-1-1 -> 2013-5-18\n",
    "# print(listDate)\n",
    "### showing heatmap\n",
    "# print(listSeason)\n",
    "# counter_season = 0\n",
    "# seasons = []\n",
    "# while counter_season < len(listSeason):\n",
    "# #     if counter_season % 10 == 0:\n",
    "#     if listSeason[counter_season] == \"12\" or listSeason[counter_season] == \"01\" or listSeason[counter_season] == \"02\":\n",
    "#         seasons += ['winter']\n",
    "#     elif listSeason[counter_season] == \"03\" or listSeason[counter_season] == \"04\" or listSeason[counter_season] == \"05\":\n",
    "#         seasons += ['spring']\n",
    "#     elif listSeason[counter_season] == \"06\" or listSeason[counter_season] == \"07\" or listSeason[counter_season] == \"08\":\n",
    "#         seasons += ['summer']   \n",
    "#     else:\n",
    "#         seasons += ['autumn']\n",
    "#     counter_season += 1\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(20,20))\n",
    "# # fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# # heatmap_vector = ax.matshow(np_mat)\n",
    "# ax.matshow(np_mat)\n",
    "\n",
    "######################################### Feature vector Visualization ####################################################\n",
    "# fig2 = plt.figure(figsize=(20,20))\n",
    "# ax2 = fig2.add_subplot(111)\n",
    "# ax2.matshow(np_mat)\n",
    "# # ax2.matshow(np_mat_topbottom_transpose)\n",
    "# ax2.set_yticklabels(listDate)\n",
    "# ax2.yaxis.set_major_locator(ticker.MultipleLocator(6))\n",
    "# # plt.savefig('Heatmap_VEC_2012_with_date.png')\n",
    "\n",
    "# fig3 = plt.figure(figsize=(20,20))\n",
    "# ax3 = fig3.add_subplot(111)\n",
    "# ax3.matshow(np_mat_topbottom)\n",
    "# # ax3.matshow(np_mat2)\n",
    "# # ax3.matshow(np_mat)\n",
    "# ax3.set_xticklabels(listDate_for_topbottom)\n",
    "# ax3.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "# # plt.savefig('Heatmap_VEC_2012_with_date_top_bottom.png')\n",
    "###########################################################################################################################\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def agglomerativeClustering(heatmapArray, feature_vector):\n",
    "    model_ac = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
    "    cluster_labels = model_ac.fit_predict(feature_vector)\n",
    "    params = model_ac.get_params(deep=True)\n",
    "    linkage_cluster = hierarchy.linkage(feature_vector, 'ward')\n",
    "    \n",
    "    plt.title('Agglomerative Clustering On Trajectory Data Pool')\n",
    "    plt.xlabel('Footsteps Count')\n",
    "    plt.ylabel('Number of Days')\n",
    "#     dendrogram = hierarchy.dendrogram(linkage_cluster, p= 5, truncate_mode='level', color_threshold=50, show_leaf_counts=False)\n",
    "#     dendrogram = hierarchy.dendrogram(linkage_cluster)\n",
    "    max_d = 3000\n",
    "    dendrogram = fancy_dendrogram(linkage_cluster, p=6, truncate_mode='level', show_leaf_counts = False, max_d=max_d)\n",
    "    clusters = hierarchy.fcluster(linkage_cluster, max_d, criterion='distance')\n",
    "#     plt.savefig('Fancy Dendrogram.png')\n",
    "    plt.show()\n",
    "    print((clusters))\n",
    "    print((cluster_labels))\n",
    "    \n",
    "    # create x-axis\n",
    "    counter_x = 0\n",
    "    x_axis = []\n",
    "    feature_axis = []\n",
    "    feature_axis_counter = collections.Counter(cluster_labels)\n",
    "    while counter_x < len(feature_axis_counter):\n",
    "        x_axis += [counter_x]\n",
    "        feature_axis += [feature_axis_counter[counter_x]]\n",
    "        counter_x += 1\n",
    "    \n",
    "    \n",
    "    plt.hist(x_axis, feature_axis)\n",
    "    plt.show()\n",
    "#     plt.savefig('scatterplot for clustering')\n",
    "#     plt.show()\n",
    "#     print(feature_vector)\n",
    "#     print(cluster_labels)\n",
    "#     print(params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# Reference #############\n",
    "# Original Author: https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "#####################################\n",
    "\n",
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = hierarchy.dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heatmapPooling(heatmapArray, pooling_dim):\n",
    "    array_of_pooled_images = []\n",
    "    yDim = heatmapArray.shape[0]\n",
    "    xDim = heatmapArray.shape[1]\n",
    "    pool_i = 0\n",
    "    start_i = 0\n",
    "    \n",
    "    # pooling from top to bottom\n",
    "    while start_i < yDim:\n",
    "        pool_j = 0\n",
    "        start_j = 0\n",
    "        pool_i += pooling_dim\n",
    "        while start_j < xDim:\n",
    "            pool_j += pooling_dim\n",
    "            pooled_image = heatmapArray[start_i:pool_i, start_j:pool_j]\n",
    "            array_of_pooled_images += [pooled_image]\n",
    "            start_j = pool_j\n",
    "        start_i = pool_i\n",
    "        \n",
    "    start_i = 0\n",
    "    pool_i = 0\n",
    "    array_of_pooled_images_topbottom = []\n",
    "    \n",
    "    # pooling from left to right\n",
    "    while start_i < xDim:\n",
    "        pool_j = 0\n",
    "        start_j = 0\n",
    "        pool_i += pooling_dim\n",
    "        while start_j < yDim:\n",
    "            pool_j += pooling_dim\n",
    "            pooled_image = heatmapArray[start_j:pool_j, start_i:pool_i]\n",
    "            array_of_pooled_images_topbottom += [pooled_image]\n",
    "            start_j = pool_j\n",
    "            print(start_j)\n",
    "        start_i = pool_i\n",
    "        \n",
    "    array_of_pooled_images = np.array(array_of_pooled_images)\n",
    "    array_of_pooled_images_topbottom = np.array(array_of_pooled_images_topbottom)\n",
    "    vector_array_pooled_images = np.concatenate(array_of_pooled_images)\n",
    "    vector_array_pooled_images = np.concatenate(vector_array_pooled_images)\n",
    "    \n",
    "#     print((array_of_pooled_images))\n",
    "   \n",
    "    \n",
    "#     sum_array = np.sum(array_of_pooled_images)\n",
    "    rowCounter = 0\n",
    "#     sum_array = np.empty([array_of_pooled_images.shape[0], 2])\n",
    "    sum_array = []\n",
    "    sum_array_top_bottom = []\n",
    "    \n",
    "    while rowCounter < array_of_pooled_images.shape[0]:\n",
    "        sum_of_pool = array_of_pooled_images[rowCounter]\n",
    "        sum_of_pool_top_bottom = array_of_pooled_images_topbottom[rowCounter]\n",
    "#         np.set_printoptions(threshold=np.nan)\n",
    "#         print(array_of_pooled_images[rowCounter].max())\n",
    "#         print(array_of_pooled_images[rowCounter])\n",
    "        sum_of_pool = np.sum(sum_of_pool)\n",
    "        sum_of_pool_top_bottom = np.sum(sum_of_pool_top_bottom)\n",
    "          # log function\n",
    "#         sum_of_pool = np.add(sum_of_pool, 1)\n",
    "#         sum_of_pool = np.log(sum_of_pool)\n",
    "#         print(sum_of_pool)\n",
    "\n",
    "#         sum_array = np.insert(sum_array, [rowCounter, 2], [rowCounter+1,sum_of_pool])\n",
    "        sum_array += [(rowCounter),(sum_of_pool)]\n",
    "        sum_array_top_bottom += [(rowCounter), (sum_of_pool_top_bottom)]\n",
    "        rowCounter += 1\n",
    "#     print(\"new array\")\n",
    "    sum_array = np.asarray(sum_array)\n",
    "    sum_array_top_bottom = np.asarray(sum_array_top_bottom)\n",
    "#     print(sum_array.shape)\n",
    "    sum_array = np.reshape(sum_array, (int(sum_array.shape[0])/2,2))\n",
    "    sum_array_top_bottom = np.reshape(sum_array_top_bottom, (int(sum_array_top_bottom.shape[0])/2,2))\n",
    "    sum_array = np.transpose(sum_array)\n",
    "    sum_array_top_bottom = np.transpose(sum_array_top_bottom)\n",
    "    sum_array = sum_array[1]\n",
    "    sum_array_top_bottom = sum_array_top_bottom[1]\n",
    "#     sum_array_transpose = sum_array.transpose()\n",
    "#     print(sum_array_transpose)\n",
    "    \n",
    "    return vector_array_pooled_images, sum_array, sum_array_top_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def histogram(heatmapArray):\n",
    "    plt.figure\n",
    "    hist_Heatmap = cv2.calcHist([heatmapArray], [3], None, [256], [0, 256])\n",
    "    plt.plot(hist_Heatmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0, 0, 0])\n",
    "\n",
    "def constructHeatmap(heatmapDataInput): \n",
    "    heatmapData = heatmapDataInput[['X','Y']]\n",
    "    heatmapData = pd.DataFrame.as_matrix(heatmapData)\n",
    "    heatmapData_X = heatmapDataInput[['X']]\n",
    "    heatmapData_Y = heatmapDataInput[['Y']]\n",
    "    heatmapData_X = pd.DataFrame.as_matrix(heatmapData_X)\n",
    "    heatmapData_X = heatmapData_X.flatten()\n",
    "    heatmapData_Y = pd.DataFrame.as_matrix(heatmapData_Y)\n",
    "    heatmapData_Y = heatmapData_Y.flatten()\n",
    "    \n",
    "    heatmapData = heatmapData.flatten()\n",
    "\n",
    "    #insert data for scaling the heatmap\n",
    "    heatmapData_X = np.insert(heatmapData_X, [0], 0) #Min cap\n",
    "    heatmapData_X = np.append(heatmapData_X, 640) #Max cap\n",
    "    heatmapData_Y = np.insert(heatmapData_Y, [0], 0) #Min cap\n",
    "    heatmapData_Y = np.append(heatmapData_Y, 480) #Max cap\n",
    "    xmin = 0\n",
    "    xmax = 640\n",
    "    ymin = 0\n",
    "    ymax = 480\n",
    "    \n",
    "    ########### hexbin approach ##########\n",
    "#     %matplotlib notebook\n",
    "# #     dataHeat = plt.hexbin(heatmapData_X, heatmapData_Y, gridsize=(640,480), xscale='linear', yscale='linear')\n",
    "#     dataHeat = plt.hexbin(heatmapData_X, heatmapData_Y)\n",
    "#     plt.axis([xmin, xmax, ymin, ymax])\n",
    "# #     plt.colorbar()\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.savefig('heatmap.png')\n",
    "    ######################################\n",
    "    \n",
    "    ########## try histogram2d approach ############\n",
    "    dataHistogram = np.histogram2d(heatmapData_X, heatmapData_Y, bins=[640,480])\n",
    "    ###########################################\n",
    "\n",
    "    ##################### Overlaying image #########################\n",
    "#     %matplotlib notebook\n",
    "#     imageA = cv2.imread(\"heatmap.png\")\n",
    "#     dim = (640, 480)\n",
    "#     imageA = cv2.resize(imageA, dim)\n",
    "#     imageB = cv2.imread(\"overlayingImage.png\")\n",
    "#     imageC = cv2.add(imageA, imageB)\n",
    "#     cv2.imshow(\"heatmap\", imageC)\n",
    "#     cv2.waitKey(0)\n",
    "    return dataHistogram[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trackID_reindex(dataframe_to_be_reindexed, currentIndex):\n",
    "    counter = 1\n",
    "    \n",
    "    ## Newly indexed Series\n",
    "    trackID_Series = dataframe_to_be_reindexed[['TrackID']]\n",
    "    trackID_Series.loc[0].TrackID = currentIndex\n",
    "    \n",
    "    ## reference Series\n",
    "    ref_Series = dataframe_to_be_reindexed[['TrackID']]\n",
    "    initial_ID = ref_Series.loc[0].TrackID\n",
    "    \n",
    "    while counter < len(dataframe_to_be_reindexed):\n",
    "        if ref_Series.loc[counter].TrackID == initial_ID:\n",
    "            trackID_Series.loc[counter].TrackID = currentIndex\n",
    "        else:\n",
    "            currentIndex += 1\n",
    "            trackID_Series.loc[counter].TrackID = currentIndex\n",
    "            initial_ID = ref_Series.loc[counter].TrackID\n",
    "        counter += 1\n",
    "    currentIndex += 1 ##for new document\n",
    "    dataframe_to_be_reindexed[['TrackID']] = trackID_Series    \n",
    "    return dataframe_to_be_reindexed, currentIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calendarFunction(currentYear, currentMonth, currentDay, pointerMonth, pointerDay):\n",
    "    if (pointerMonth == 3) or (pointerMonth == 5) or (pointerMonth == 8) or (pointerMonth == 10):\n",
    "        if currentDay == '30':\n",
    "            currentDay = dayArray[0]\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "            pointerDay = 0\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "            \n",
    "    elif pointerMonth == 1:\n",
    "        if (currentYear%4 == 0) and (currentDay == '28'):#leapyear\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "        elif (currentYear%4 == 0) and (currentDay == '29'):#reset to 01 if day ends for the month\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        elif (currentYear%4 != 0) and (currentDay == '28'): #Non Leap year\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "    else: #for 31 days month\n",
    "        if currentDay == '30':\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "        elif currentDay == '31':\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "\n",
    "    #if year ends?\n",
    "    if (pointerMonth == 11) and (pointerDay == 30):\n",
    "        currentYear += 1\n",
    "        pointerMonth = 0\n",
    "        pointerDay = 0\n",
    "        currentMonth = monthArray[pointerMonth]\n",
    "        currentDay = dayArray[pointerDay]\n",
    "    return currentYear, currentMonth, currentDay, pointerMonth, pointerDay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
