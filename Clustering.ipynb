{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ice\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:66: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_reduce'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-d267fea80b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mclusteredTracks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadTraclusExport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LOST3output.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# print(clusteredTracks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mgradient_DF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusteredTracks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrajectoryID_Extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusteredTracks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-b5875ae222fd>\u001b[0m in \u001b[0;36mcalculateVector\u001b[1;34m(dataframeInput)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempNP_splitter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtempDF_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempDF_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframeInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_pivot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtempNP_splitter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mtempDF_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempDF_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mtempDF_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempDF_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempDF_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ice\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   5307\u001b[0m             return self._agg_by_level(name, axis=axis, level=level,\n\u001b[0;32m   5308\u001b[0m                                       skipna=skipna)\n\u001b[1;32m-> 5309\u001b[1;33m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0m\u001b[0;32m   5310\u001b[0m                             numeric_only=numeric_only)\n\u001b[0;32m   5311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_reduce'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas import Series, DataFrame, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc \n",
    "import os\n",
    "\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "# Tunable Variables\n",
    "days_to_process = 7\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# Loading data\n",
    "col_names = ['TrackID','FrameNo', 'X', 'Y']\n",
    "# day1 = pd.read_table(\"001_20130101.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day2 = pd.read_table(\"001_20130102.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day3 = pd.read_table(\"001_20130103.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day4 = pd.read_table(\"001_20130104.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day5 = pd.read_table(\"001_20130105.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day6 = pd.read_table(\"001_20130106.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "# day7 = pd.read_table(\"001_20130107.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "\n",
    "day1 = pd.read_table(\"001_20130212.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day2 = pd.read_table(\"001_20130214.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day3 = pd.read_table(\"001_20130215.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day4 = pd.read_table(\"001_20130216.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day5 = pd.read_table(\"001_20130217.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day6 = pd.read_table(\"001_20130218.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "day7 = pd.read_table(\"001_20130219.txt\",delimiter=\" \", header=None, names=col_names)\n",
    "\n",
    "frames = [day1, day2, day3, day4, day5, day6, day7]\n",
    "concatDay = pd.concat(frames, ignore_index=True)\n",
    "# concatDay = concatDay.sort_values(by='TrackID', ascending=True)\n",
    "# concatDay\n",
    "# TraClusFileExporter(concatDay)\n",
    "\n",
    "\n",
    "clusteredTracks = ReadTraclusExport('LOST3output.txt')\n",
    "# print(clusteredTracks)\n",
    "gradient_DF = calculateVector(clusteredTracks)\n",
    "\n",
    "cluster = TrajectoryID_Extraction(clusteredTracks)\n",
    "# print(cluster)\n",
    "# colors_for_lines = ColorAssignment(cluster)\n",
    "colors_for_lines = ColorAssignment(clusteredTracks)\n",
    "# print(colors_for_lines)\n",
    "# cluster_line = LinesConstruct(cluster)\n",
    "cluster_line = LinesConstruct(clusteredTracks)\n",
    "# np.set_printoptions(threshold='nan')\n",
    "# print(colors_for_lines)\n",
    "\n",
    "Visualizer(cluster_line, colors_for_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateGradient(dataframeInput):\n",
    "    tempnp = pd.DataFrame.as_matrix(dataframeInput[['X']])\n",
    "    tempnp = tempnp.ravel()\n",
    "    dataframe_gradient_X = np.gradient(tempnp)\n",
    "    \n",
    "    tempnp = pd.DataFrame.as_matrix(dataframeInput[['Y']])\n",
    "    tempnp = tempnp.ravel()\n",
    "    dataframe_gradient_Y = np.gradient(tempnp)\n",
    "    \n",
    "    return dataframe_gradient_X, dataframe_gradient_Y\n",
    "    \n",
    "def calculateVector(dataframeInput):\n",
    "    ################# Data preps##############################\n",
    "\n",
    "    ##########################################################\n",
    "    \n",
    "    #####################Separate clusters for mean calculation################################\n",
    "    tempNP_splitter = []\n",
    "    pivot = 0\n",
    "    pivoted_cluster_id = dataframeInput[['TrackID']].loc[pivot]\n",
    "    pivoted_cluster_id = pivoted_cluster_id.TrackID\n",
    "    while pivot < len(dataframeInput):        \n",
    "        current_cluster_id = dataframeInput[['TrackID']].loc[pivot]\n",
    "        current_cluster_id = current_cluster_id.TrackID\n",
    "        if current_cluster_id != pivoted_cluster_id:\n",
    "            tempNP_splitter += [pivot]\n",
    "            pivoted_cluster_id = current_cluster_id\n",
    "        pivot += 1\n",
    "    print(tempNP_splitter)\n",
    "    \n",
    "    counter = 0\n",
    "    current_pivot = 0\n",
    "    while counter < len(tempNP_splitter):\n",
    "        tempDF_X, tempDF_Y = calculateGradient(dataframeInput[current_pivot:tempNP_splitter[counter]])\n",
    "        tempDF_X = pd.DataFrame.mean(tempDF_X, axis = 0)\n",
    "        tempDF_Y = pd.DataFrame.mean(tempDF_Y, axis = 0)\n",
    "        print(tempDF_X)\n",
    "        current_pivot = tempNP_splitter[counter] + 1\n",
    "        counter += 1\n",
    "    ###########################################################################################\n",
    "    \n",
    "    ################## Average gradient for each cluster##############\n",
    "    temp_grad_X = pd.DataFrame.mean(dataframeInput[['X']], axis = 0)\n",
    "    temp_grad_Y = pd.DataFrame.mean(dataframeInput[['Y']], axis = 0)\n",
    "    ##################################################################\n",
    "    \n",
    "    ######## Print statements\n",
    "#     print(temp_grad_X)\n",
    "    ######################## Plotting ###################################\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.quiver(dataframeInput[['X']], dataframeInput[['Y']], temp_grad_X, temp_grad_Y)\n",
    "    plt.show()\n",
    "    #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-dbff7f68ef4f>:33: SyntaxWarning: name 'end' is assigned to before global declaration\n",
      "  global end, lines_ori\n",
      "<ipython-input-3-dbff7f68ef4f>:33: SyntaxWarning: name 'lines_ori' is assigned to before global declaration\n",
      "  global end, lines_ori\n"
     ]
    }
   ],
   "source": [
    "# Get the output from TraClus, revamp and prepare data to visualize\n",
    "# to achieve this, i need to read from text file and reconstruct it back to a dataframe.\n",
    "def ReadTraclusExport(filename):\n",
    "    fileOpener = open(filename, 'r')\n",
    "    lines_ori = fileOpener.readlines()\n",
    "\n",
    "    ########Choose the rows with X Y coordinates####################################\n",
    "    #a loop is needed to differentiate the xy and affilitated trajectory's id\n",
    "    counterLineNumber = 0 \n",
    "    for lines in lines_ori:\n",
    "        indexOfTraj = lines.find(\"trajectoryID: 0\")\n",
    "        if indexOfTraj == 0:\n",
    "            break\n",
    "        counterLineNumber += 1\n",
    "\n",
    "    start = 2\n",
    "    end = counterLineNumber \n",
    "    step = 2\n",
    "    lines = lines_ori[start:end:step]\n",
    "    ################################################################################\n",
    "\n",
    "    ####################Choose the rows with ID and number of points################\n",
    "    clusterID_array = []\n",
    "    num_points = []\n",
    "    start = 1\n",
    "    end = counterLineNumber\n",
    "    step = 2\n",
    "    lines_ID = lines_ori[start:end:step]\n",
    "    length_lines_ID = len(lines_ID)\n",
    "    counter_for_linesID = 0\n",
    "    \n",
    "    #a global list for accessment\n",
    "    global end, lines_ori\n",
    "    \n",
    "    while counter_for_linesID < length_lines_ID:\n",
    "        temp_lines_ID = str(lines_ID[counter_for_linesID])\n",
    "        temp_index = temp_lines_ID.find(\" \")\n",
    "        temp_index3 = temp_lines_ID.find(\"P\")\n",
    "        temp_index2 = temp_lines_ID.find(\"  \", 14, len(temp_lines_ID))\n",
    "        clusterID_array += [temp_lines_ID[temp_index + 1:temp_index3]]\n",
    "        num_points += [temp_lines_ID[temp_index2 + 2:]]\n",
    "        counter_for_linesID += 1\n",
    "    ##################################################################################\n",
    "\n",
    "    #Strip the string into appropriate form\n",
    "    element = str(lines)\n",
    "    elementText = element[0:-1]\n",
    "    elementText = str.replace(elementText, '\\\\' , '')\n",
    "    elementText = str.replace(elementText, \"n\", '')\n",
    "    elementText = str.replace(elementText, \"   \", \" \")\n",
    "    elementText = str.replace(elementText, \",\", \"\\n\")\n",
    "    elementText = str.replace(elementText, \"\\n\", '')\n",
    "    elementText = str.replace(elementText, \"'\", \"\" )\n",
    "    elementText = str.replace(elementText, \"  \",\" \")\n",
    "    elementText = str.replace(elementText, \"[\", \"\")\n",
    "\n",
    "    #put in 2d array form and convert to integer\n",
    "    numpyString = np.fromstring(elementText, dtype=float, sep= ' ' or '\\n')\n",
    "    numpyInt = numpyString.astype(int)\n",
    "    number_of_rows = int( len(numpyInt)/2 )\n",
    "    numpyInt = numpyInt.reshape((number_of_rows,2))\n",
    "\n",
    "    #convert numpy array to dataframe\n",
    "    dataframeInt = pd.DataFrame(numpyInt)\n",
    "    dataframeInt.columns = ['X', 'Y']\n",
    "    dataframeInt = dataframeInt.convert_objects(convert_numeric=True)\n",
    "\n",
    "    #Assign ID to specific tracks\n",
    "    temp_array_ID = []\n",
    "    total_num_points = len(num_points)\n",
    "    counter_for_total_num = 0\n",
    "    while counter_for_total_num < total_num_points:\n",
    "        tempCounter_for_num = 0\n",
    "        while tempCounter_for_num < int(num_points[counter_for_total_num]):\n",
    "            temp_array_ID += [clusterID_array[counter_for_total_num]]\n",
    "            tempCounter_for_num += 1\n",
    "        counter_for_total_num += 1\n",
    "\n",
    "    #finalized output\n",
    "    temp_array_ID = list(map(int, temp_array_ID))\n",
    "    dataframeInt['TrackID'] = temp_array_ID\n",
    "    cols = dataframeInt.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataframeInt = dataframeInt[cols]\n",
    "\n",
    "    return dataframeInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decide the color for each cluster\n",
    "##########stripping the trajectory id#################\n",
    "def TrajectoryID_Extraction(dataframeInt):\n",
    "    startTraj_ID = end + 1\n",
    "    endTraj_ID = len(lines_ori)\n",
    "    stepTraj_ID = 2\n",
    "    traj_ID = lines_ori[startTraj_ID:endTraj_ID:stepTraj_ID]\n",
    "    counter_cluster_ID = 0\n",
    "    array_for_cluster_ID = []\n",
    "    count_for_cluster_ID = []\n",
    "    ## Form ***clusterID***\n",
    "\n",
    "    while counter_cluster_ID < len(traj_ID):\n",
    "        count_cluster_ID = 0\n",
    "        number_of_string = traj_ID[counter_cluster_ID].count(' ')\n",
    "        while count_cluster_ID < number_of_string:\n",
    "            array_for_cluster_ID += [counter_cluster_ID]\n",
    "            count_cluster_ID += 1\n",
    "        counter_cluster_ID += 1\n",
    "    array_for_cluster_ID = pd.DataFrame(array_for_cluster_ID)\n",
    "    \n",
    "    #sample: elementText = str.replace(elementText, '\\\\' , '')\n",
    "    #sample: numpyString = np.fromstring(elementText, dtype=float, sep= ' ' or '\\n')\n",
    "    #sample\" dataframeInt = pd.DataFrame(numpyInt)\n",
    "    ## Stripping string to form ***trajectoryID***\n",
    "    traj_ID = str(traj_ID)\n",
    "    traj_ID = str.replace(traj_ID, '[\\'', '')\n",
    "    traj_ID = str.replace(traj_ID, '\\']', '')\n",
    "    traj_ID = str.replace(traj_ID, ', ', '\\n')\n",
    "    traj_ID = str.replace(traj_ID, '\\\\n', '')\n",
    "    traj_ID = str.replace(traj_ID, '\\'', '')\n",
    "    traj_ID = np.fromstring(traj_ID, dtype=int, sep=' ')\n",
    "    traj_ID = pd.DataFrame(traj_ID)\n",
    "    traj_ID.columns = ['TrackID']\n",
    "    traj_ID['ClusterID'] = array_for_cluster_ID\n",
    "    ######################################################\n",
    "\n",
    "    #check the matched value through joining\n",
    "#     print(traj_ID)\n",
    "    tempDF = pd.DataFrame()\n",
    "    tempDF = pd.merge(concatDay, traj_ID, on='TrackID')\n",
    "    return tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ColorAssignment(dataframe):\n",
    "\n",
    "    try:\n",
    "        dataframe[['ClusterID']]\n",
    "    except:\n",
    "#         dataframe = LinesConstruct(dataframe)        \n",
    "        dataframe = dataframe.rename(columns={'TrackID': 'ClusterID'})\n",
    "    \n",
    "\n",
    "    ########################Assign Color##################\n",
    "    tempColor = np.where(dataframe['ClusterID'] == 0, 'blue', \n",
    "                         np.where( dataframe['ClusterID'] == 1, 'yellow', \n",
    "                                  np.where(dataframe['ClusterID'] == 2, 'cyan',\n",
    "                                           np.where(dataframe['ClusterID'] == 3, 'magenta','black'))))    \n",
    "    counter = 1\n",
    "    helper_color = tempColor[0]\n",
    "    tempColor2 = []\n",
    "    tempColor2 += [helper_color]\n",
    "    while counter < len(tempColor):\n",
    "        if helper_color != tempColor[counter]:\n",
    "            tempColor2 += [tempColor[counter]]\n",
    "            helper_color = tempColor[counter]\n",
    "        counter += 1\n",
    "\n",
    "    return tempColor2\n",
    "    ######################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct lines for visualization in plot\n",
    "def LinesConstruct(dataFrameSelected):\n",
    "    #assignment without colors for all days\n",
    "    # dataframeInt = concatDay\n",
    "    #assignment with colors for all days\n",
    "#     dataframeInt = tempDF\n",
    "\n",
    "    #if clustered, then just comment out both lines above\n",
    "    # tempColor = np.where(dataframeInt['TrackID'] == 0, 'blue', \n",
    "    #                      np.where( dataframeInt['TrackID'] == 1, 'yellow', \n",
    "    #                               np.where(dataframeInt['TrackID'] == 2, 'cyan',\n",
    "    #                                        np.where(dataframeInt['TrackID'] == 3, 'magenta','black'))))   \n",
    "\n",
    "    concatenator = dataFrameSelected[['TrackID','X','Y']]\n",
    "    concatenator2 = dataFrameSelected[['X', 'Y']]\n",
    "\n",
    "    row_iterator = concatenator.iterrows()\n",
    "    row_id, this_row = next(row_iterator)\n",
    "    #slicing dataframe to respective arrays for LineCollection function\n",
    "    initialID = this_row['TrackID']\n",
    "    slicingArray = []\n",
    "    for i, rows in row_iterator:\n",
    "        if rows['TrackID'] != initialID:\n",
    "            slicingArray.append(i)\n",
    "            initialID = rows['TrackID']\n",
    "\n",
    "    testChamp = np.split( concatenator2, slicingArray )\n",
    "    testChampSize = len(testChamp)\n",
    "    dummyTest2 = list(testChamp)\n",
    "#     print(dummyTest2)\n",
    "    ###only applicable to clustered colors\n",
    "\n",
    "    return dummyTest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare .tra extension file for TraClus clustering algorithm\n",
    "def TraClusFileExporter(concatDay):\n",
    "    outputFile = []\n",
    "    concatDay = concatDay[['TrackID', 'X', 'Y']]\n",
    "    concatDayWithoutID = concatDay[['X', 'Y']]\n",
    "    concatDayWithID = concatDay[['TrackID']]\n",
    "    concatDayWithID = concatDayWithID.drop_duplicates('TrackID')\n",
    "    concatDayWithID = concatDayWithID.values  #it's an array now\n",
    "\n",
    "\n",
    "    # slicing the dataframe based on ID\n",
    "    row_iterator = concatDay.iterrows()\n",
    "    row_id, this_row = next(row_iterator)\n",
    "    #slicing dataframe to respective arrays for LineCollection function\n",
    "    initialID = this_row['TrackID']\n",
    "    slicingArray = []\n",
    "\n",
    "    ####################suspected bug################################\n",
    "    for i, rows in row_iterator:\n",
    "        if rows['TrackID'] != initialID:\n",
    "            slicingArray.append(i)\n",
    "            initialID = rows['TrackID']\n",
    "\n",
    "    newList = np.split( concatDayWithoutID, slicingArray )\n",
    "\n",
    "    ####################suspected bug################################\n",
    "\n",
    "    #Now: We need to combine every single piece of data to conform with .tra\n",
    "    #header: number of dimensions\n",
    "    #      : number of trajectories\n",
    "    number_of_dimension = 2\n",
    "    number_of_trajectory = len(concatDayWithID)\n",
    "    arrayForHeader = str(number_of_dimension) + '\\n' + str(number_of_trajectory) + '\\n'\n",
    "#     print(concatDayWithID)\n",
    "    #format: TrackID no_trajectory_point X1 Y1 X2 Y2... Xn Yn\n",
    "    arrayForXY = []\n",
    "    number_of_ID = len(concatDayWithID)\n",
    "    counter_for_points = 0\n",
    "    counter_for_ID = 0\n",
    "\n",
    "    while counter_for_ID < number_of_ID:\n",
    "        # reset\n",
    "        counter_for_points = 0\n",
    "        # Convert ID to proper string form\n",
    "        tempID = concatDayWithID[counter_for_ID]\n",
    "        number_of_trajectory_points = len(newList[counter_for_ID])\n",
    "        stringForTempID = str(tempID)\n",
    "        stringForTempID = stringForTempID[1:-1]\n",
    "        # concatenation\n",
    "        if len(arrayForXY) == 0:\n",
    "            arrayForXY = stringForTempID + ' ' + str(number_of_trajectory_points) + ' '\n",
    "        else:\n",
    "            arrayForXY += stringForTempID + ' ' + str(number_of_trajectory_points) + ' '\n",
    "        while counter_for_points < number_of_trajectory_points:  \n",
    "            # Select X and Y\n",
    "            tempHelper = newList[counter_for_ID]\n",
    "            tempArray = tempHelper.iloc[counter_for_points]\n",
    "            helperX = tempArray[0]\n",
    "            helperY = tempArray[1]\n",
    "            arrayForXY += str(helperX) + ' ' + str(helperY) + ' '\n",
    "            counter_for_points += 1\n",
    "            if counter_for_points == number_of_trajectory_points:\n",
    "                arrayForXY += '\\n'\n",
    "        counter_for_ID += 1\n",
    "\n",
    "    finalOutput = arrayForHeader + arrayForXY    \n",
    "\n",
    "    output = open('LOST3.tra', 'w')\n",
    "    output.write(finalOutput)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Visualizer(list_of_lines, lineColor):\n",
    "    indices = [0, 1]\n",
    "    counterForLineConstruction = 0\n",
    "\n",
    "    #line preparation\n",
    "    #### Visualize line with Color\n",
    "    linesegment = mc.LineCollection(list_of_lines, linewidths = 2, linestyles='solid', colors=lineColor)\n",
    "    #### Visualize line without Color\n",
    "    # linesegment = mc.LineCollection(dataframeInt, linewidths = 2, linestyles='solid', colors='black')\n",
    "    #### Visualize an arrow\n",
    "\n",
    "\n",
    "\n",
    "    #canvas setup\n",
    "    x = np.arange(641)\n",
    "    ys = x[0:480, np.newaxis]\n",
    "\n",
    "    # set plot limits\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    ax.set_ylim(ys.min(), ys.max())\n",
    "    ax.add_collection(linesegment)\n",
    "    plt.gca().invert_yaxis()\n",
    "    im = plt.imread('overlayingImage.png')\n",
    "    implot = plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
