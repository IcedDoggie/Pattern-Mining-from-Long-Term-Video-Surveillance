{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Documents\\MMU Studies\\Python Scripts\\Track LOST dataset\n",
      "Yes!\n",
      "Yes!\n",
      "Yes!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ice\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:66: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-227-36c178833216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mtest_subject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mnj_parameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnj_training_parameter\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mconcatDay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusteredTracks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0mcalculateSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusteredTracks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_subject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnj_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m# average_grad_X, average_grad_Y = calculateVector(clusteredTracks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-223-dabb193283b4>\u001b[0m in \u001b[0;36mnj_training_parameter\u001b[1;34m(training_track, representative_track)\u001b[0m\n\u001b[0;32m     21\u001b[0m                                              representative_track[ pivot_list2[representative_counter]:pivot_list2[representative_counter + 1] ])\n\u001b[0;32m     22\u001b[0m             \u001b[0mtracks_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcombined_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_track\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbottom_param\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mparameter_nj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcombined_param\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mrepresentative_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas import Series, DataFrame, Panel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as fig\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import collections as mc \n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess\n",
    "import math\n",
    "\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "##################################### Tunable Variables ###########################################\n",
    "days_to_process = 7\n",
    "pd.options.display.max_rows = 10\n",
    "###################################################################################################\n",
    "\n",
    "#####################################string variables##############################################\n",
    "dayArray = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17'\n",
    ",'18','19','20','21','22','23','24','25','26','27','28','29','30','31']\n",
    "monthArray = ['01','02','03','04','05','06','07','08','09','10','11','12',]\n",
    "# Tunable Variables\n",
    "# currentYear = 2013 # input 1\n",
    "# pointerMonth = n n1\t   # input 2\n",
    "# pointerDay = 0   # input 3\n",
    "\n",
    "currentYear = 2013\n",
    "currentMonth = monthArray[0]\n",
    "currentDay = dayArray[0]\n",
    "pointerMonth = 0\n",
    "pointerDay = 0\n",
    "daysToChoose = 3\n",
    "#####################################################################################################\n",
    "\n",
    "###############################string concatenation & Load Data########################\n",
    "counter = 0\n",
    "frames = pd.DataFrame()\n",
    "os.chdir('E:\\Documents\\MMU Studies\\Python Scripts\\Track LOST dataset')\n",
    "currentIndex = 1 # This variable is used to reindex every dataframe\n",
    "print(os.getcwd())\n",
    "while counter < daysToChoose:\n",
    "    stringDate = '001_' + str(currentYear) + str(currentMonth) + str(currentDay) + '.txt' \n",
    "    string_to_be_parsed = \"pd.read_table('\" + stringDate + \"',delimiter=' ', header=None, names=col_names)\"\n",
    "    try:\n",
    "        exec(\"%s%d = %s\" % (\"day\", counter, string_to_be_parsed))\n",
    "        tempString_Date = eval(\"%s%d\" % (\"day\", counter))   \n",
    "        tempString_Date, currentIndex = trackID_reindex(tempString_Date, currentIndex)\n",
    "        frames = frames.append(tempString_Date)\n",
    "        print(\"Yes!\")\n",
    "    except:\n",
    "        counter -= 1\n",
    "        print(\"Nope!\")\n",
    "    counter += 1\n",
    "    currentYear, currentMonth, currentDay, pointerMonth, pointerDay = calendarFunction(currentYear, currentMonth, currentDay, pointerMonth, pointerDay)\n",
    "#######################################################################################\n",
    "\n",
    "col_names = ['TrackID', 'FrameNo', 'X', 'Y']\n",
    "# concatDay = pd.concat(frames, ignore_index=True) #this shud be removed cuz frames no longer is np array, it's pd df now.\n",
    "concatDay = frames.sort_values(by='TrackID', ascending=True)\n",
    "concatDay = concatDay.reset_index(drop=True)\n",
    "os.chdir('E:\\Documents\\MMU Studies\\Python Scripts')\n",
    "\n",
    "# TraClusFileExporter(concatDay, \"LOST_365_Days.tra\")\n",
    "# dataTraining()\n",
    "# ##################################Clustering##########################################\n",
    "\n",
    "clusteredTracks = ReadTraclusExport('LOST4Output.txt')\n",
    "test_subject = np.array([[200,300],[100,150]])\n",
    "\n",
    "nj_parameter = nj_training_parameter( concatDay, clusteredTracks)\n",
    "calculateSimilarity(clusteredTracks, test_subject, nj_parameter)\n",
    "# average_grad_X, average_grad_Y = calculateVector(clusteredTracks)\n",
    "\n",
    "# #For All Clusters\n",
    "# cluster = TrajectoryID_Extraction(clusteredTracks)\n",
    "# colors_for_lines = ColorAssignment(clusteredTracks)\n",
    "# cluster_line = LinesConstruct(clusteredTracks)\n",
    "# Visualizer(cluster_line, colors_for_lines)\n",
    "\n",
    "#For Separate cluster\n",
    "# cluster = TrajectoryID_Extraction(clusteredTracks)\n",
    "# colors_for_lines = ColorAssignment(cluster)\n",
    "# cluster_line = LinesConstruct(cluster)\n",
    "# Visualizer(cluster_line, colors_for_lines)\n",
    "\n",
    "# ######################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateSimilarity(representative_trajectory, new_trajectory, parameter_nj):\n",
    "    \n",
    "    # splitting tracks based on id\n",
    "    representative_trajectory, pivot_list = trajectory_pivoting_based_on_id(representative_trajectory)\n",
    "    \n",
    "    representative_trajectory = pd.DataFrame.as_matrix(representative_trajectory)\n",
    "\n",
    "    tracks_counter = 0\n",
    "    probability_array = []\n",
    "    \n",
    "#         print((representative_trajectory[ tempNP_splitter[tracks_counter]:tempNP_splitter[tracks_counter+1] ]))\n",
    "#         print(tracks)\n",
    "#     for each in parameter_nj:\n",
    "    while tracks_counter < len(pivot_list) - 1:\n",
    "        probability_array += [math.exp( (-parameter_nj[tracks_counter]) * chamfer_distance(new_trajectory,representative_trajectory[ pivot_list[tracks_counter]:pivot_list[tracks_counter+1] ]))]\n",
    "        tracks_counter += 1\n",
    "#     print(parameter_nj)\n",
    "    print(probability_array)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nj_training_parameter(training_track, representative_track):\n",
    "    \n",
    "    # calculate each of the training track chamfer distance\n",
    "    parameter_nj = []\n",
    "    training_track, pivot_list = trajectory_pivoting_based_on_id(training_track)\n",
    "    \n",
    "    representative_track, pivot_list2 = trajectory_pivoting_based_on_id(representative_track)\n",
    "    \n",
    "    # convert to numpy\n",
    "    training_track = pd.DataFrame.as_matrix(training_track)\n",
    "    representative_track = pd.DataFrame.as_matrix(representative_track)\n",
    "    \n",
    "    tracks_counter = 0\n",
    "    representative_counter = 0\n",
    "    \n",
    "    \n",
    "    while representative_counter < len(pivot_list2) - 1:\n",
    "        bottom_param = 0\n",
    "        while tracks_counter < len(pivot_list) - 1:\n",
    "            bottom_param += chamfer_distance(training_track[pivot_list[tracks_counter]:pivot_list[tracks_counter + 1]],\n",
    "                                             representative_track[ pivot_list2[representative_counter]:pivot_list2[representative_counter + 1] ])\n",
    "            tracks_counter += 1\n",
    "        if bottom_param >0:    \n",
    "            combined_param = len(training_track) / bottom_param\n",
    "        parameter_nj += [combined_param]\n",
    "        representative_counter += 1\n",
    "    print(bottom_param)\n",
    "    \n",
    "    return parameter_nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trajectory_pivoting_based_on_id(trajectory_dataframe):\n",
    "    tempNP_splitter = []\n",
    "    tempNP_splitter += [0]\n",
    "    pivot = 0\n",
    "    pivoted_cluster_id = trajectory_dataframe[['TrackID']].loc[pivot]\n",
    "    pivoted_cluster_id = pivoted_cluster_id.TrackID\n",
    "    while pivot < len(trajectory_dataframe):        \n",
    "        current_cluster_id = trajectory_dataframe[['TrackID']].loc[pivot]\n",
    "        current_cluster_id = current_cluster_id.TrackID\n",
    "        if current_cluster_id != pivoted_cluster_id:\n",
    "            tempNP_splitter += [pivot]\n",
    "            pivoted_cluster_id = current_cluster_id\n",
    "        pivot += 1\n",
    "    tempNP_splitter += [len(trajectory_dataframe)]\n",
    "    trajectory = trajectory_dataframe[['X','Y']]        \n",
    "    return trajectory, tempNP_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chamfer_distance(track_p, track_q):\n",
    "     \n",
    "    first_term = ( 1 / abs(len(track_p)) )\n",
    "\n",
    "    difference_tp_tq = []\n",
    "    for points in track_p:\n",
    "        temp_dist = np.subtract(track_q[:,0], points[0])\n",
    "        temp_dist2 = np.subtract(track_q[:,1], points[1])\n",
    "        temp_dist = np.add(temp_dist, temp_dist2)\n",
    "        temp_dist = np.power(temp_dist, 2)\n",
    "        temp_dist = min(temp_dist)\n",
    "        difference_tp_tq += [temp_dist]\n",
    "#     print(difference_tp_tq)\n",
    "    second_term = sum(difference_tp_tq)    \n",
    "    \n",
    "    distance = first_term * second_term\n",
    "    \n",
    "#     print(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateGradient(dataframeInput):\n",
    "    tempnp = pd.DataFrame.as_matrix(dataframeInput[['X']])\n",
    "    tempnp = tempnp.ravel()\n",
    "    dataframe_gradient_X = np.gradient(tempnp)\n",
    "    \n",
    "    tempnp = pd.DataFrame.as_matrix(dataframeInput[['Y']])\n",
    "    tempnp = tempnp.ravel()\n",
    "    dataframe_gradient_Y = np.gradient(tempnp)\n",
    "    \n",
    "    x = dataframeInput[['X']].loc[2]\n",
    "    y = dataframeInput[['Y']].loc[2]\n",
    "    print(x)\n",
    "    print(y)\n",
    "    euclideanNorm = math.hypot(x, y)\n",
    "    print(euclideanNorm)\n",
    "    return dataframe_gradient_X, dataframe_gradient_Y\n",
    "    \n",
    "def calculateVector(dataframeInput):\n",
    "    #####################Separate clusters for mean calculation################################\n",
    "    tempNP_splitter = []\n",
    "    pivot = 0\n",
    "    pivoted_cluster_id = dataframeInput[['TrackID']].loc[pivot]\n",
    "    pivoted_cluster_id = pivoted_cluster_id.TrackID\n",
    "    while pivot < len(dataframeInput):        \n",
    "        current_cluster_id = dataframeInput[['TrackID']].loc[pivot]\n",
    "        current_cluster_id = current_cluster_id.TrackID\n",
    "        if current_cluster_id != pivoted_cluster_id:\n",
    "            tempNP_splitter += [pivot]\n",
    "            pivoted_cluster_id = current_cluster_id\n",
    "        pivot += 1\n",
    "    \n",
    "    counter = 0\n",
    "    current_pivot = 0\n",
    "    visualize_np_X = np.empty(0)\n",
    "    visualize_np_Y = np.empty(0)\n",
    "    average_np_X = np.empty(0)\n",
    "    average_np_Y = np.empty(0)\n",
    "    \n",
    "    while counter <= len(tempNP_splitter):\n",
    "        try:\n",
    "            tempDF_X, tempDF_Y = calculateGradient(dataframeInput[current_pivot:tempNP_splitter[counter]])\n",
    "\n",
    "        except:\n",
    "            tempDF_X, tempDF_Y = calculateGradient(dataframeInput[current_pivot:(dataframeInput.iloc[-1].name + 1)])\n",
    "        try:\n",
    "            current_pivot = tempNP_splitter[counter]\n",
    "        except:\n",
    "            current_pivot = 0\n",
    "        visualize_np_X = np.append(visualize_np_X, tempDF_X)\n",
    "        visualize_np_Y = np.append(visualize_np_Y, tempDF_Y)\n",
    "        tempDF_X = np.mean(tempDF_X)\n",
    "        tempDF_Y = np.mean(tempDF_Y)\n",
    "        average_np_X = np.append(average_np_X, tempDF_X)\n",
    "        average_np_Y = np.append(average_np_Y, tempDF_Y)\n",
    "        counter += 1\n",
    "\n",
    "    ###########################################################################################\n",
    "    \n",
    "    ################## Average gradient for each cluster##############\n",
    "    temp_grad_X = pd.DataFrame.mean(dataframeInput[['X']], axis = 0)\n",
    "    temp_grad_Y = pd.DataFrame.mean(dataframeInput[['Y']], axis = 0)\n",
    "    ##################################################################\n",
    "    \n",
    "    \n",
    "    ######################## Plotting ###################################\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.quiver(dataframeInput[['X']], dataframeInput[['Y']], visualize_np_X, visualize_np_Y)\n",
    "#     plt.quiver(average_np_X, average_np_Y)\n",
    "    plt.show()\n",
    "    #####################################################################\n",
    "    return average_np_X, average_np_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataTraining():\n",
    "    os.chdir('E:\\Documents\\MMU Studies\\Python Scripts\\TraClusAlgorithm\\src')\n",
    "    print(\"Running TraClus Algorithm...\")\n",
    "    subprocess.call(\"dir\",shell=True)\n",
    "#     sys.getopt(LOST_30_Days)\n",
    "    os.chdir('E:\\Documents\\MMU Studies\\Python Scripts')\n",
    "    subprocess.call(\"echo \" + os.getcwd(), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trackID_reindex(dataframe_to_be_reindexed, currentIndex):\n",
    "    counter = 1\n",
    "    \n",
    "    ## Newly indexed Series\n",
    "    trackID_Series = dataframe_to_be_reindexed[['TrackID']]\n",
    "    trackID_Series.loc[0].TrackID = currentIndex\n",
    "    \n",
    "    ## reference Series\n",
    "    ref_Series = dataframe_to_be_reindexed[['TrackID']]\n",
    "    initial_ID = ref_Series.loc[0].TrackID\n",
    "    \n",
    "    while counter < len(dataframe_to_be_reindexed):\n",
    "        if ref_Series.loc[counter].TrackID == initial_ID:\n",
    "            trackID_Series.loc[counter].TrackID = currentIndex\n",
    "        else:\n",
    "            currentIndex += 1\n",
    "            trackID_Series.loc[counter].TrackID = currentIndex\n",
    "            initial_ID = ref_Series.loc[counter].TrackID\n",
    "        counter += 1\n",
    "    currentIndex += 1 ##for new document\n",
    "    dataframe_to_be_reindexed[['TrackID']] = trackID_Series    \n",
    "    return dataframe_to_be_reindexed, currentIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calendarFunction(currentYear, currentMonth, currentDay, pointerMonth, pointerDay):\n",
    "    if (pointerMonth == 3) or (pointerMonth == 5) or (pointerMonth == 8) or (pointerMonth == 10):\n",
    "        if currentDay == '30':\n",
    "            currentDay = dayArray[0]\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "            pointerDay = 0\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "            \n",
    "    elif pointerMonth == 1:\n",
    "        if (currentYear%4 == 0) and (currentDay == '28'):#leapyear\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "        elif (currentYear%4 == 0) and (currentDay == '29'):#reset to 01 if day ends for the month\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        elif (currentYear%4 != 0) and (currentDay == '28'): #Non Leap year\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "    else: #for 31 days month\n",
    "        if currentDay == '30':\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "        elif currentDay == '31':\n",
    "            currentDay = dayArray[0]\n",
    "            pointerDay = 0\n",
    "            pointerMonth += 1\n",
    "            currentMonth = monthArray[pointerMonth]\n",
    "        else:\n",
    "            pointerDay += 1\n",
    "            currentDay = dayArray[pointerDay]\n",
    "\n",
    "    #if year ends?\n",
    "    if (pointerMonth == 11) and (pointerDay == 30):\n",
    "        currentYear += 1\n",
    "        pointerMonth = 0\n",
    "        pointerDay = 0\n",
    "        currentMonth = monthArray[pointerMonth]\n",
    "        currentDay = dayArray[pointerDay]\n",
    "    return currentYear, currentMonth, currentDay, pointerMonth, pointerDay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageOverlaying(imageA, imageB):\n",
    "    image1 = plt.imread(imageA)\n",
    "    image2 = plt.imread(imageB)\n",
    "    imgCombination = image1 + image2\n",
    "    return imgCombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dbff7f68ef4f>:33: SyntaxWarning: name 'end' is assigned to before global declaration\n",
      "  global end, lines_ori\n",
      "<ipython-input-9-dbff7f68ef4f>:33: SyntaxWarning: name 'lines_ori' is assigned to before global declaration\n",
      "  global end, lines_ori\n"
     ]
    }
   ],
   "source": [
    "# Get the output from TraClus, revamp and prepare data to visualize\n",
    "# to achieve this, i need to read from text file and reconstruct it back to a dataframe.\n",
    "def ReadTraclusExport(filename):\n",
    "    fileOpener = open(filename, 'r')\n",
    "    lines_ori = fileOpener.readlines()\n",
    "\n",
    "    ########Choose the rows with X Y coordinates####################################\n",
    "    #a loop is needed to differentiate the xy and affilitated trajectory's id\n",
    "    counterLineNumber = 0 \n",
    "    for lines in lines_ori:\n",
    "        indexOfTraj = lines.find(\"trajectoryID: 0\")\n",
    "        if indexOfTraj == 0:\n",
    "            break\n",
    "        counterLineNumber += 1\n",
    "\n",
    "    start = 2\n",
    "    end = counterLineNumber \n",
    "    step = 2\n",
    "    lines = lines_ori[start:end:step]\n",
    "    ################################################################################\n",
    "\n",
    "    ####################Choose the rows with ID and number of points################\n",
    "    clusterID_array = []\n",
    "    num_points = []\n",
    "    start = 1\n",
    "    end = counterLineNumber\n",
    "    step = 2\n",
    "    lines_ID = lines_ori[start:end:step]\n",
    "    length_lines_ID = len(lines_ID)\n",
    "    counter_for_linesID = 0\n",
    "    \n",
    "    #a global list for accessment\n",
    "    global end, lines_ori\n",
    "    \n",
    "    while counter_for_linesID < length_lines_ID:\n",
    "        temp_lines_ID = str(lines_ID[counter_for_linesID])\n",
    "        temp_index = temp_lines_ID.find(\" \")\n",
    "        temp_index3 = temp_lines_ID.find(\"P\")\n",
    "        temp_index2 = temp_lines_ID.find(\"  \", 14, len(temp_lines_ID))\n",
    "        clusterID_array += [temp_lines_ID[temp_index + 1:temp_index3]]\n",
    "        num_points += [temp_lines_ID[temp_index2 + 2:]]\n",
    "        counter_for_linesID += 1\n",
    "    ##################################################################################\n",
    "\n",
    "    #Strip the string into appropriate form\n",
    "    element = str(lines)\n",
    "    elementText = element[0:-1]\n",
    "    elementText = str.replace(elementText, '\\\\' , '')\n",
    "    elementText = str.replace(elementText, \"n\", '')\n",
    "    elementText = str.replace(elementText, \"   \", \" \")\n",
    "    elementText = str.replace(elementText, \",\", \"\\n\")\n",
    "    elementText = str.replace(elementText, \"\\n\", '')\n",
    "    elementText = str.replace(elementText, \"'\", \"\" )\n",
    "    elementText = str.replace(elementText, \"  \",\" \")\n",
    "    elementText = str.replace(elementText, \"[\", \"\")\n",
    "\n",
    "    #put in 2d array form and convert to integer\n",
    "    numpyString = np.fromstring(elementText, dtype=float, sep= ' ' or '\\n')\n",
    "    numpyInt = numpyString.astype(int)\n",
    "    number_of_rows = int( len(numpyInt)/2 )\n",
    "    numpyInt = numpyInt.reshape((number_of_rows,2))\n",
    "\n",
    "    #convert numpy array to dataframe\n",
    "    dataframeInt = pd.DataFrame(numpyInt)\n",
    "    dataframeInt.columns = ['X', 'Y']\n",
    "    dataframeInt = dataframeInt.convert_objects(convert_numeric=True)\n",
    "\n",
    "    #Assign ID to specific tracks\n",
    "    temp_array_ID = []\n",
    "    total_num_points = len(num_points)\n",
    "    counter_for_total_num = 0\n",
    "    while counter_for_total_num < total_num_points:\n",
    "        tempCounter_for_num = 0\n",
    "        while tempCounter_for_num < int(num_points[counter_for_total_num]):\n",
    "            temp_array_ID += [clusterID_array[counter_for_total_num]]\n",
    "            tempCounter_for_num += 1\n",
    "        counter_for_total_num += 1\n",
    "\n",
    "    #finalized output\n",
    "    temp_array_ID = list(map(int, temp_array_ID))\n",
    "    dataframeInt['TrackID'] = temp_array_ID\n",
    "    cols = dataframeInt.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    dataframeInt = dataframeInt[cols]\n",
    "\n",
    "    return dataframeInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decide the color for each cluster\n",
    "##########stripping the trajectory id#################\n",
    "def TrajectoryID_Extraction(dataframeInt):\n",
    "    startTraj_ID = end + 1\n",
    "    endTraj_ID = len(lines_ori)\n",
    "    stepTraj_ID = 2\n",
    "    traj_ID = lines_ori[startTraj_ID:endTraj_ID:stepTraj_ID]\n",
    "    counter_cluster_ID = 0\n",
    "    array_for_cluster_ID = []\n",
    "    count_for_cluster_ID = []\n",
    "    ## Form ***clusterID***\n",
    "\n",
    "    while counter_cluster_ID < len(traj_ID):\n",
    "        count_cluster_ID = 0\n",
    "        number_of_string = traj_ID[counter_cluster_ID].count(' ')\n",
    "        while count_cluster_ID < number_of_string:\n",
    "            array_for_cluster_ID += [counter_cluster_ID]\n",
    "            count_cluster_ID += 1\n",
    "        counter_cluster_ID += 1\n",
    "    array_for_cluster_ID = pd.DataFrame(array_for_cluster_ID)\n",
    "    \n",
    "    #sample: elementText = str.replace(elementText, '\\\\' , '')\n",
    "    #sample: numpyString = np.fromstring(elementText, dtype=float, sep= ' ' or '\\n')\n",
    "    #sample\" dataframeInt = pd.DataFrame(numpyInt)\n",
    "    ## Stripping string to form ***trajectoryID***\n",
    "    traj_ID = str(traj_ID)\n",
    "    traj_ID = str.replace(traj_ID, '[\\'', '')\n",
    "    traj_ID = str.replace(traj_ID, '\\']', '')\n",
    "    traj_ID = str.replace(traj_ID, ', ', '\\n')\n",
    "    traj_ID = str.replace(traj_ID, '\\\\n', '')\n",
    "    traj_ID = str.replace(traj_ID, '\\'', '')\n",
    "    traj_ID = np.fromstring(traj_ID, dtype=int, sep=' ')\n",
    "    traj_ID = pd.DataFrame(traj_ID)\n",
    "    traj_ID.columns = ['TrackID']\n",
    "    traj_ID['ClusterID'] = array_for_cluster_ID\n",
    "    ######################################################\n",
    "\n",
    "    #check the matched value through joining\n",
    "#     print(traj_ID)\n",
    "    tempDF = pd.DataFrame()\n",
    "    tempDF = pd.merge(concatDay, traj_ID, on='TrackID')\n",
    "    return tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ColorAssignment(dataframe):\n",
    "\n",
    "    try:\n",
    "        dataframe[['ClusterID']]\n",
    "    except:\n",
    "#         dataframe = LinesConstruct(dataframe)        \n",
    "        dataframe = dataframe.rename(columns={'TrackID': 'ClusterID'})\n",
    "    \n",
    "\n",
    "    ########################Assign Color##################\n",
    "    tempColor = np.where(dataframe['ClusterID'] == 0, 'blue', \n",
    "                         np.where( dataframe['ClusterID'] == 1, 'yellow', \n",
    "                                  np.where(dataframe['ClusterID'] == 2, 'cyan',\n",
    "                                           np.where(dataframe['ClusterID'] == 3, 'magenta','black'))))    \n",
    "    counter = 1\n",
    "    helper_color = tempColor[0]\n",
    "    tempColor2 = []\n",
    "    tempColor2 += [helper_color]\n",
    "    while counter < len(tempColor):\n",
    "        if helper_color != tempColor[counter]:\n",
    "            tempColor2 += [tempColor[counter]]\n",
    "            helper_color = tempColor[counter]\n",
    "        counter += 1\n",
    "\n",
    "    return tempColor2\n",
    "    ######################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct lines for visualization in plot\n",
    "def LinesConstruct(dataFrameSelected):\n",
    "    concatenator = dataFrameSelected[['TrackID','X','Y']]\n",
    "    concatenator2 = dataFrameSelected[['X', 'Y']]\n",
    "\n",
    "    row_iterator = concatenator.iterrows()\n",
    "    row_id, this_row = next(row_iterator)\n",
    "    #slicing dataframe to respective arrays for LineCollection function\n",
    "    initialID = this_row['TrackID']\n",
    "    slicingArray = []\n",
    "    for i, rows in row_iterator:\n",
    "        if rows['TrackID'] != initialID:\n",
    "            slicingArray.append(i)\n",
    "            initialID = rows['TrackID']\n",
    "\n",
    "    testChamp = np.split( concatenator2, slicingArray )\n",
    "    testChampSize = len(testChamp)\n",
    "    dummyTest2 = list(testChamp)\n",
    "    return dummyTest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare .tra extension file for TraClus clustering algorithm\n",
    "def TraClusFileExporter(concatDay, filename):\n",
    "    outputFile = []\n",
    "    concatDay = concatDay[['TrackID', 'X', 'Y']]\n",
    "    concatDayWithoutID = concatDay[['X', 'Y']]\n",
    "    concatDayWithID = concatDay[['TrackID']]\n",
    "    concatDayWithID = concatDayWithID.drop_duplicates('TrackID')\n",
    "    concatDayWithID = concatDayWithID.values  #it's an array now\n",
    "\n",
    "\n",
    "    # slicing the dataframe based on ID\n",
    "    row_iterator = concatDay.iterrows()\n",
    "    row_id, this_row = next(row_iterator)\n",
    "    #slicing dataframe to respective arrays for LineCollection function\n",
    "    initialID = this_row['TrackID']\n",
    "    slicingArray = []\n",
    "\n",
    "    ####################suspected bug################################\n",
    "    for i, rows in row_iterator:\n",
    "        if rows['TrackID'] != initialID:\n",
    "            slicingArray.append(i)\n",
    "            initialID = rows['TrackID']\n",
    "\n",
    "    newList = np.split( concatDayWithoutID, slicingArray )\n",
    "\n",
    "    ####################suspected bug################################\n",
    "\n",
    "    #Now: We need to combine every single piece of data to conform with .tra\n",
    "    #header: number of dimensions\n",
    "    #      : number of trajectories\n",
    "    number_of_dimension = 2\n",
    "    number_of_trajectory = len(concatDayWithID)\n",
    "    arrayForHeader = str(number_of_dimension) + '\\n' + str(number_of_trajectory) + '\\n'\n",
    "#     print(concatDayWithID)\n",
    "    #format: TrackID no_trajectory_point X1 Y1 X2 Y2... Xn Yn\n",
    "    arrayForXY = []\n",
    "    number_of_ID = len(concatDayWithID)\n",
    "    counter_for_points = 0\n",
    "    counter_for_ID = 0\n",
    "\n",
    "    while counter_for_ID < number_of_ID:\n",
    "        # reset\n",
    "        counter_for_points = 0\n",
    "        # Convert ID to proper string form\n",
    "        tempID = concatDayWithID[counter_for_ID]\n",
    "        number_of_trajectory_points = len(newList[counter_for_ID])\n",
    "        stringForTempID = str(tempID)\n",
    "        stringForTempID = stringForTempID[1:-1]\n",
    "        # concatenation\n",
    "        if len(arrayForXY) == 0:\n",
    "            arrayForXY = stringForTempID + ' ' + str(number_of_trajectory_points) + ' '\n",
    "        else:\n",
    "            arrayForXY += stringForTempID + ' ' + str(number_of_trajectory_points) + ' '\n",
    "        while counter_for_points < number_of_trajectory_points:  \n",
    "            # Select X and Y\n",
    "            tempHelper = newList[counter_for_ID]\n",
    "            tempArray = tempHelper.iloc[counter_for_points]\n",
    "            helperX = tempArray[0]\n",
    "            helperY = tempArray[1]\n",
    "            arrayForXY += str(helperX) + ' ' + str(helperY) + ' '\n",
    "            counter_for_points += 1\n",
    "            if counter_for_points == number_of_trajectory_points:\n",
    "                arrayForXY += '\\n'\n",
    "        counter_for_ID += 1\n",
    "\n",
    "    finalOutput = arrayForHeader + arrayForXY    \n",
    "\n",
    "    output = open(filename, 'w')\n",
    "    output.write(finalOutput)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Visualizer(list_of_lines, lineColor):\n",
    "    indices = [0, 1]\n",
    "    counterForLineConstruction = 0\n",
    "\n",
    "    #line preparation\n",
    "    #### Visualize line with Color\n",
    "    linesegment = mc.LineCollection(list_of_lines, linewidths = 2, linestyles='solid', colors=lineColor)\n",
    "    #### Visualize line without Color\n",
    "    # linesegment = mc.LineCollection(dataframeInt, linewidths = 2, linestyles='solid', colors='black')\n",
    "    #### Visualize an arrow\n",
    "\n",
    "\n",
    "\n",
    "    #canvas setup\n",
    "    x = np.arange(641)\n",
    "    ys = x[0:480, np.newaxis]\n",
    "\n",
    "    # set plot limits\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    ax.set_ylim(ys.min(), ys.max())\n",
    "    ax.add_collection(linesegment)\n",
    "    plt.gca().invert_yaxis()\n",
    "    im = plt.imread('overlayingImage.png')\n",
    "    implot = plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
